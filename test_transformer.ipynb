{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_norm(df, col_exclude=None):\n",
    "    \"\"\"Performs z-score normalization on all columns of df except col_exclude\n",
    "    \n",
    "    inputs:\n",
    "        df: stock data\n",
    "        col_exclude: columns to be excluded from normalization\n",
    "        \n",
    "    returns:\n",
    "        df_std: normalized z-score data\n",
    "    \"\"\"\n",
    "\n",
    "    df_std = df.copy()\n",
    "    cols = list(df.columns)\n",
    "    cols.remove(col_exclude)\n",
    "    for c in cols:\n",
    "        df_std[c] = (df_std[c] - df_std[c].mean()) / df_std[c].std()\n",
    "\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequences(seq_size: int, obs: np.array):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(obs) - seq_size):\n",
    "        window = obs[i:(i + seq_size), :]\n",
    "        after_window = obs[i + seq_size, :]\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data_path = 'data'\n",
    "interval = '1d'\n",
    "companies = ['AAPL'] #os.listdir(data_path)\n",
    "df_list = []\n",
    "test_start_date = pd.to_datetime(\"2022-03-01\")\n",
    "for co in companies:\n",
    "    files = os.listdir(os.path.join(data_path, co))\n",
    "    for f in files:\n",
    "        if interval in f:\n",
    "            file = f\n",
    "\n",
    "    df = pd.read_csv(os.path.join(data_path, co, file))\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    df = z_norm(df, 'date')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # could also add ticker label column\n",
    "\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "seq_size = 30 # 30th day will be the prediction\n",
    "for df in df_list:\n",
    "    # split each df into train and test timeframes\n",
    "    df_train = df[df['date'] < test_start_date]\n",
    "    df_test = df[df['date'] >= test_start_date]\n",
    "\n",
    "    # drop unnecessary columns\n",
    "    df_train = df.drop(columns=['date'])\n",
    "    df_test = df.drop(columns=['date'])\n",
    "\n",
    "    # convert to 2D numpy arrays of shape (-1, num_cols)\n",
    "    train = df_train.to_numpy()\n",
    "    test = df_test.to_numpy()\n",
    "\n",
    "    # convert to sequences and append to respective training and testing lists\n",
    "    x, y = to_sequences(seq_size, train)\n",
    "    for i in range(len(x)):\n",
    "        x_train.append(x[i])\n",
    "        y_train.append(y[i])\n",
    "    x, y = to_sequences(seq_size, test)\n",
    "    for j in range(len(x)):\n",
    "        x_test.append(x[i])\n",
    "        y_test.append(y[i])\n",
    "\n",
    "\n",
    "x_train = np.vstack(x_train)\n",
    "y_train = np.vstack(y_train)\n",
    "x_test = np.vstack(x_test)\n",
    "y_test = np.vstack(y_test)\n",
    "\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72120, 19])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2404, 19])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2434, 19)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='date').to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>close_RSI_14</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>AROOND_25</th>\n",
       "      <th>AROONU_25</th>\n",
       "      <th>AROONOSC_25</th>\n",
       "      <th>CCI_14_0.015</th>\n",
       "      <th>CG_14</th>\n",
       "      <th>close_HMA_50</th>\n",
       "      <th>ISA_9</th>\n",
       "      <th>ISB_26</th>\n",
       "      <th>ITS_9</th>\n",
       "      <th>IKS_26</th>\n",
       "      <th>VWAP_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>1.467021</td>\n",
       "      <td>1.487340</td>\n",
       "      <td>1.471476</td>\n",
       "      <td>1.502690</td>\n",
       "      <td>-0.672981</td>\n",
       "      <td>1.089309</td>\n",
       "      <td>-0.596104</td>\n",
       "      <td>0.707591</td>\n",
       "      <td>1.302202</td>\n",
       "      <td>-0.417201</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>-0.446298</td>\n",
       "      <td>-0.983596</td>\n",
       "      <td>1.515545</td>\n",
       "      <td>1.662439</td>\n",
       "      <td>1.553527</td>\n",
       "      <td>1.558826</td>\n",
       "      <td>1.633761</td>\n",
       "      <td>1.487310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>1.539030</td>\n",
       "      <td>1.514396</td>\n",
       "      <td>1.517844</td>\n",
       "      <td>1.496872</td>\n",
       "      <td>-0.714855</td>\n",
       "      <td>-0.167325</td>\n",
       "      <td>-0.635560</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>1.188451</td>\n",
       "      <td>-0.526497</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>-0.141296</td>\n",
       "      <td>-0.806672</td>\n",
       "      <td>1.510124</td>\n",
       "      <td>1.683299</td>\n",
       "      <td>1.554449</td>\n",
       "      <td>1.558826</td>\n",
       "      <td>1.633761</td>\n",
       "      <td>1.509772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>1.468786</td>\n",
       "      <td>1.455746</td>\n",
       "      <td>1.456317</td>\n",
       "      <td>1.442917</td>\n",
       "      <td>-0.617830</td>\n",
       "      <td>-1.081952</td>\n",
       "      <td>-0.987749</td>\n",
       "      <td>0.221406</td>\n",
       "      <td>1.074699</td>\n",
       "      <td>-0.635793</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>-0.713634</td>\n",
       "      <td>-0.844285</td>\n",
       "      <td>1.503768</td>\n",
       "      <td>1.701872</td>\n",
       "      <td>1.554449</td>\n",
       "      <td>1.553797</td>\n",
       "      <td>1.633761</td>\n",
       "      <td>1.451736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>2022-03-07</td>\n",
       "      <td>1.448842</td>\n",
       "      <td>1.446494</td>\n",
       "      <td>1.401746</td>\n",
       "      <td>1.374680</td>\n",
       "      <td>-0.443517</td>\n",
       "      <td>-1.377569</td>\n",
       "      <td>-1.370813</td>\n",
       "      <td>-0.255807</td>\n",
       "      <td>0.960948</td>\n",
       "      <td>-0.745089</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>-1.097908</td>\n",
       "      <td>-0.979837</td>\n",
       "      <td>1.494215</td>\n",
       "      <td>1.697846</td>\n",
       "      <td>1.562099</td>\n",
       "      <td>1.528298</td>\n",
       "      <td>1.633761</td>\n",
       "      <td>1.407871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>1.368714</td>\n",
       "      <td>1.409140</td>\n",
       "      <td>1.343965</td>\n",
       "      <td>1.341884</td>\n",
       "      <td>0.033852</td>\n",
       "      <td>-0.707117</td>\n",
       "      <td>-1.536119</td>\n",
       "      <td>-0.708693</td>\n",
       "      <td>0.847197</td>\n",
       "      <td>-0.854385</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>-1.494674</td>\n",
       "      <td>-0.973183</td>\n",
       "      <td>1.481119</td>\n",
       "      <td>1.706355</td>\n",
       "      <td>1.562099</td>\n",
       "      <td>1.517164</td>\n",
       "      <td>1.633761</td>\n",
       "      <td>1.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>2.011151</td>\n",
       "      <td>1.991972</td>\n",
       "      <td>2.009341</td>\n",
       "      <td>1.989518</td>\n",
       "      <td>-1.015277</td>\n",
       "      <td>-0.151478</td>\n",
       "      <td>0.353225</td>\n",
       "      <td>0.291933</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>-1.400864</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>0.718580</td>\n",
       "      <td>0.883301</td>\n",
       "      <td>1.855859</td>\n",
       "      <td>1.790252</td>\n",
       "      <td>1.878453</td>\n",
       "      <td>2.078873</td>\n",
       "      <td>2.029718</td>\n",
       "      <td>1.996990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>1.994384</td>\n",
       "      <td>1.965615</td>\n",
       "      <td>1.988476</td>\n",
       "      <td>1.958661</td>\n",
       "      <td>-1.155866</td>\n",
       "      <td>-0.558825</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.034404</td>\n",
       "      <td>0.164691</td>\n",
       "      <td>-1.510160</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>0.389352</td>\n",
       "      <td>0.764184</td>\n",
       "      <td>1.863877</td>\n",
       "      <td>1.801276</td>\n",
       "      <td>1.878453</td>\n",
       "      <td>2.090006</td>\n",
       "      <td>2.045270</td>\n",
       "      <td>1.970942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>1.954496</td>\n",
       "      <td>1.920929</td>\n",
       "      <td>1.946388</td>\n",
       "      <td>1.946495</td>\n",
       "      <td>-1.120793</td>\n",
       "      <td>-0.256669</td>\n",
       "      <td>-0.120828</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>0.050940</td>\n",
       "      <td>-1.619455</td>\n",
       "      <td>-0.946970</td>\n",
       "      <td>0.066453</td>\n",
       "      <td>0.728426</td>\n",
       "      <td>1.871797</td>\n",
       "      <td>1.823691</td>\n",
       "      <td>1.878453</td>\n",
       "      <td>2.090006</td>\n",
       "      <td>2.051419</td>\n",
       "      <td>1.937955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>1.935612</td>\n",
       "      <td>1.913947</td>\n",
       "      <td>1.908759</td>\n",
       "      <td>1.881432</td>\n",
       "      <td>-1.001019</td>\n",
       "      <td>-1.128587</td>\n",
       "      <td>-0.742393</td>\n",
       "      <td>-0.162676</td>\n",
       "      <td>-0.062811</td>\n",
       "      <td>-1.619455</td>\n",
       "      <td>-0.884935</td>\n",
       "      <td>-0.285407</td>\n",
       "      <td>0.537001</td>\n",
       "      <td>1.877500</td>\n",
       "      <td>1.833847</td>\n",
       "      <td>1.878453</td>\n",
       "      <td>2.090006</td>\n",
       "      <td>2.070317</td>\n",
       "      <td>1.901499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>1.866779</td>\n",
       "      <td>1.831907</td>\n",
       "      <td>1.853118</td>\n",
       "      <td>1.817250</td>\n",
       "      <td>-1.006402</td>\n",
       "      <td>-1.134811</td>\n",
       "      <td>-1.227293</td>\n",
       "      <td>-0.439956</td>\n",
       "      <td>-0.176562</td>\n",
       "      <td>0.566461</td>\n",
       "      <td>0.417809</td>\n",
       "      <td>-0.880318</td>\n",
       "      <td>0.258837</td>\n",
       "      <td>1.879461</td>\n",
       "      <td>1.862712</td>\n",
       "      <td>1.878453</td>\n",
       "      <td>2.090006</td>\n",
       "      <td>2.080716</td>\n",
       "      <td>1.834114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      open      high       low     close    volume  pct_change   \n",
       "1952 2022-03-02  1.467021  1.487340  1.471476  1.502690 -0.672981    1.089309  \\\n",
       "1953 2022-03-03  1.539030  1.514396  1.517844  1.496872 -0.714855   -0.167325   \n",
       "1954 2022-03-04  1.468786  1.455746  1.456317  1.442917 -0.617830   -1.081952   \n",
       "1955 2022-03-07  1.448842  1.446494  1.401746  1.374680 -0.443517   -1.377569   \n",
       "1956 2022-03-08  1.368714  1.409140  1.343965  1.341884  0.033852   -0.707117   \n",
       "...         ...       ...       ...       ...       ...       ...         ...   \n",
       "2429 2024-01-25  2.011151  1.991972  2.009341  1.989518 -1.015277   -0.151478   \n",
       "2430 2024-01-26  1.994384  1.965615  1.988476  1.958661 -1.155866   -0.558825   \n",
       "2431 2024-01-29  1.954496  1.920929  1.946388  1.946495 -1.120793   -0.256669   \n",
       "2432 2024-01-30  1.935612  1.913947  1.908759  1.881432 -1.001019   -1.128587   \n",
       "2433 2024-01-31  1.866779  1.831907  1.853118  1.817250 -1.006402   -1.134811   \n",
       "\n",
       "      close_RSI_14  ADOSC_3_10  AROOND_25  AROONU_25  AROONOSC_25   \n",
       "1952     -0.596104    0.707591   1.302202  -0.417201    -0.946970  \\\n",
       "1953     -0.635560    0.492100   1.188451  -0.526497    -0.946970   \n",
       "1954     -0.987749    0.221406   1.074699  -0.635793    -0.946970   \n",
       "1955     -1.370813   -0.255807   0.960948  -0.745089    -0.946970   \n",
       "1956     -1.536119   -0.708693   0.847197  -0.854385    -0.946970   \n",
       "...            ...         ...        ...        ...          ...   \n",
       "2429      0.353225    0.291933   0.278442  -1.400864    -0.946970   \n",
       "2430      0.010014    0.034404   0.164691  -1.510160    -0.946970   \n",
       "2431     -0.120828    0.018129   0.050940  -1.619455    -0.946970   \n",
       "2432     -0.742393   -0.162676  -0.062811  -1.619455    -0.884935   \n",
       "2433     -1.227293   -0.439956  -0.176562   0.566461     0.417809   \n",
       "\n",
       "      CCI_14_0.015     CG_14  close_HMA_50     ISA_9    ISB_26     ITS_9   \n",
       "1952     -0.446298 -0.983596      1.515545  1.662439  1.553527  1.558826  \\\n",
       "1953     -0.141296 -0.806672      1.510124  1.683299  1.554449  1.558826   \n",
       "1954     -0.713634 -0.844285      1.503768  1.701872  1.554449  1.553797   \n",
       "1955     -1.097908 -0.979837      1.494215  1.697846  1.562099  1.528298   \n",
       "1956     -1.494674 -0.973183      1.481119  1.706355  1.562099  1.517164   \n",
       "...            ...       ...           ...       ...       ...       ...   \n",
       "2429      0.718580  0.883301      1.855859  1.790252  1.878453  2.078873   \n",
       "2430      0.389352  0.764184      1.863877  1.801276  1.878453  2.090006   \n",
       "2431      0.066453  0.728426      1.871797  1.823691  1.878453  2.090006   \n",
       "2432     -0.285407  0.537001      1.877500  1.833847  1.878453  2.090006   \n",
       "2433     -0.880318  0.258837      1.879461  1.862712  1.878453  2.090006   \n",
       "\n",
       "        IKS_26    VWAP_D  \n",
       "1952  1.633761  1.487310  \n",
       "1953  1.633761  1.509772  \n",
       "1954  1.633761  1.451736  \n",
       "1955  1.633761  1.407871  \n",
       "1956  1.633761  1.365300  \n",
       "...        ...       ...  \n",
       "2429  2.029718  1.996990  \n",
       "2430  2.045270  1.970942  \n",
       "2431  2.051419  1.937955  \n",
       "2432  2.070317  1.901499  \n",
       "2433  2.080716  1.834114  \n",
       "\n",
       "[482 rows x 20 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['date'] > test_start_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using basic transformer from https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_10_3_transformer_timeseries.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition using Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.decoder(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "model = TransformerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
