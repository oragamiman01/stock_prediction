{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from StockDataWrapper import get_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableLengthDataset(Dataset):\n",
    "    def __init__(self, tickers: list[str], data_dir: str, lag_days: int, test_days: int, test: bool):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.tickers = []\n",
    "\n",
    "        num_to_ticker = dict()\n",
    "        ticker_to_num = dict()\n",
    "        ids = np.linspace(-1, 1, len(tickers)).round(5)\n",
    "        for i, num in enumerate(ids):\n",
    "            num_to_ticker[str(num)] = tickers[i]\n",
    "            ticker_to_num[tickers[i]] = num\n",
    "\n",
    "        # get the unix timestamp value for 2024-04-15. Used to scale the date value used as input to the model\n",
    "        cur_unix_timestamp = datetime.datetime(year=2024, month=4, day=15).timestamp()\n",
    "\n",
    "        for ticker in tickers:\n",
    "            ordered_time_series = get_time_series(ticker, data_dir, normalize=True)\n",
    "\n",
    "            if test:\n",
    "                idx = range(len(ordered_time_series) - lag_days - test_days, len(ordered_time_series))\n",
    "            else:\n",
    "                idx = range(lag_days, len(ordered_time_series) - lag_days - test_days)\n",
    "\n",
    "            # need to get lag_days days of input tokens and predict the lag_days+1 day, and so on\n",
    "            for cur_target_idx in idx:\n",
    "\n",
    "                # get target values\n",
    "                cur_target_actual_after = [ticker_to_num[ticker]]\n",
    "                for key in ordered_time_series[cur_target_idx]:\n",
    "\n",
    "                    val = ordered_time_series[cur_target_idx][key]\n",
    "                    if key == 'date':\n",
    "                        val = (datetime.datetime.strptime(val, \"%Y-%m-%d\").timestamp()) / cur_unix_timestamp  # scale to small value\n",
    "                    cur_target_actual_after.append(val)\n",
    "\n",
    "                # each \"sample\" (input) will have multiple tokens. Each token is a vector of the day's values\n",
    "                cur_input = []\n",
    "\n",
    "                for i in range(cur_target_idx - lag_days, cur_target_idx):\n",
    "\n",
    "                    cur_token = [ticker_to_num[ticker]]\n",
    "                    for key in ordered_time_series[cur_target_idx]:\n",
    "\n",
    "                        val = ordered_time_series[cur_target_idx][key]\n",
    "                        if key == 'date':\n",
    "                            val = (datetime.datetime.strptime(val, \"%Y-%m-%d\").timestamp()) / cur_unix_timestamp  # scale to small value\n",
    "                        cur_token.append(val)\n",
    "\n",
    "                    cur_input.append(cur_token)\n",
    "\n",
    "                self.X.append(cur_input)\n",
    "                self.y.append(cur_target_actual_after)\n",
    "                self.tickers.append(ticker)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32), self.tickers[idx]\n",
    "    \n",
    "\n",
    "class IncrementalDataset(Dataset):\n",
    "    def __init__(self, tickers: list[str], data_dir: str, lag_days: int, test_days: int, test: bool):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.tickers = []\n",
    "\n",
    "        num_to_ticker = dict()\n",
    "        ticker_to_num = dict()\n",
    "        ids = np.linspace(-1, 1, len(tickers)).round(5)\n",
    "        for i, num in enumerate(ids):\n",
    "            num_to_ticker[str(num)] = tickers[i]\n",
    "            ticker_to_num[tickers[i]] = num\n",
    "\n",
    "        # get the unix timestamp value for 2024-04-15. Used to scale the date value used as input to the model\n",
    "        cur_unix_timestamp = datetime.datetime(year=2024, month=4, day=15).timestamp()\n",
    "\n",
    "        for ticker in tickers:\n",
    "            ordered_time_series = get_time_series(ticker, data_dir, normalize=True)\n",
    "\n",
    "            if test:\n",
    "                idx = range(len(ordered_time_series) - lag_days - test_days, len(ordered_time_series) - lag_days - test_days + 1)\n",
    "            else:\n",
    "                idx = range(lag_days, len(ordered_time_series) - lag_days - test_days)\n",
    "\n",
    "            # need to get lag_days days of input tokens and predict the lag_days+1 day, and so on\n",
    "            for cur_target_idx in idx:\n",
    "\n",
    "                # get target values\n",
    "                cur_target_actual_after = [ticker_to_num[ticker]]\n",
    "                for key in ordered_time_series[cur_target_idx]:\n",
    "\n",
    "                    val = ordered_time_series[cur_target_idx][key]\n",
    "                    if key == 'date':\n",
    "                        val = (datetime.datetime.strptime(val, \"%Y-%m-%d\").timestamp()) / cur_unix_timestamp  # scale to small value\n",
    "                    cur_target_actual_after.append(val)\n",
    "\n",
    "                # each \"sample\" (input) will have multiple tokens. Each token is a vector of the day's values\n",
    "                cur_input = []\n",
    "\n",
    "                for i in range(cur_target_idx - lag_days, cur_target_idx):\n",
    "\n",
    "                    cur_token = [ticker_to_num[ticker]]\n",
    "                    for key in ordered_time_series[cur_target_idx]:\n",
    "\n",
    "                        val = ordered_time_series[cur_target_idx][key]\n",
    "                        if key == 'date':\n",
    "                            val = (datetime.datetime.strptime(val, \"%Y-%m-%d\").timestamp()) / cur_unix_timestamp  # scale to small value\n",
    "                        cur_token.append(val)\n",
    "\n",
    "                    cur_input.append(cur_token)\n",
    "\n",
    "                self.X.append(cur_input)\n",
    "                self.y.append(cur_target_actual_after)\n",
    "                self.tickers.append(ticker)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32), self.tickers[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding for Transformer (batch first)\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "class BigTransformer(nn.Module):\n",
    "    def __init__(self, indim, outdim, hidden_dim=256, d_model=64, nhead=4, num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super(BigTransformer, self).__init__()\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(indim, hidden_dim),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, d_model)\n",
    "            )\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, batch_first=True)\n",
    "\n",
    "        self.decoder_mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, hidden_dim),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, outdim)\n",
    "        )\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "    # src: (B, S, F) batches, sequence length, features\n",
    "    # tgt: (B, F)\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        tgt = self.embedding(tgt.unsqueeze(1))\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        src_mask = nn.Transformer.generate_square_subsequent_mask(src.shape[1]).to(device)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.shape[1]).to(device)\n",
    "        out = self.transformer(src, tgt, src_mask, tgt_mask, src_is_causal=True, tgt_is_causal=True)\n",
    "        out = self.decoder_mlp(out)\n",
    "        return out.squeeze(1)\n",
    "    \n",
    "    def generate(self, src, max_len=100, start_token=None, end_token=None):\n",
    "        device = src.device\n",
    "        src = self.embedding(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        src_mask = nn.Transformer.generate_square_subsequent_mask(src.shape[1]).to(device)\n",
    "\n",
    "        output_seq = torch.zeros((src.shape[0], 1, self.d_model)).to(device)\n",
    "        if start_token is not None:\n",
    "            output_seq[:, 0] = self.embedding(start_token.to(device))\n",
    "\n",
    "        for i in range(max_len):\n",
    "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(output_seq.shape[1]).to(device)\n",
    "            next_token = self.transformer(src, output_seq, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "            output_seq = torch.cat([output_seq, next_token], dim=1)\n",
    "\n",
    "            if end_token is not None and torch.all(next_token == end_token):\n",
    "                break\n",
    "            \n",
    "        output_seq = self.decoder_mlp(output_seq[:, 1:]) # exclude start token\n",
    "        \n",
    "        return output_seq.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public methods are constructor, train, evaluate, and load_model\n",
    "class BigTransformerAgent:\n",
    "    def __init__(self, indim, outdim, hidden_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, \n",
    "                 device, checkpoint_dir, init_lr, lr_decay, min_lr, decay_lr_every):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "\n",
    "        self.allow_training = True\n",
    "        self.cur_epoch = 0\n",
    "\n",
    "        self.device = device\n",
    "        self.model = BigTransformer(indim, outdim, hidden_dim, d_model, nhead, \n",
    "                                    num_encoder_layers, num_decoder_layers)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=init_lr)\n",
    "\n",
    "        # at epoch e, lr will be init_lr * scheduler_lamb(e)\n",
    "        scheduler_lamb = lambda epoch: max(lr_decay ** (epoch // decay_lr_every), min_lr / init_lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, scheduler_lamb)\n",
    "\n",
    "        self.criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        checkpoint = torch.load(model_path)\n",
    "\n",
    "        self.model.load_state_dict(checkpoint[\"model\"])\n",
    "        self.cur_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "        self.allow_training = False\n",
    "        self.model.eval()\n",
    "\n",
    "    def __save_model(self):\n",
    "        if not os.path.isdir(self.checkpoint_dir):\n",
    "            os.mkdir(self.checkpoint_dir)\n",
    "\n",
    "        dt = datetime.datetime.now().strftime(\"%m-%d_%H-%M-%S\")\n",
    "        path = os.path.join(self.checkpoint_dir, f\"{dt}_agent_{self.cur_epoch}.pth\")\n",
    "\n",
    "        params = {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"epoch\": self.cur_epoch\n",
    "        }\n",
    "\n",
    "        torch.save(params, path)\n",
    "\n",
    "    def __save_returns(self, returns):\n",
    "        returns_prefix = f\"{self.checkpoint_dir}/returns\"\n",
    "\n",
    "        if not os.path.isdir(self.checkpoint_dir):\n",
    "            os.mkdir(self.checkpoint_dir)\n",
    "        if not os.path.isdir(returns_prefix):\n",
    "            os.mkdir(returns_prefix)\n",
    "\n",
    "        np_filename = f\"{returns_prefix}/{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.npy\"\n",
    "        np.save(np_filename, returns)\n",
    "\n",
    "        return np_filename\n",
    "\n",
    "    def train(self, dataloader, epochs):\n",
    "        if not self.allow_training:\n",
    "            raise Exception(\"Not allowed to train after loading\")\n",
    "\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for (X, y, tickers) in dataloader:\n",
    "                X = X.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                y_pred = self.model(X, y)\n",
    "\n",
    "                loss = self.criterion(y, y_pred)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # TODO is this good?\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            # self.scheduler.step()\n",
    "\n",
    "            losses.append(epoch_loss)\n",
    "\n",
    "            self.cur_epoch += 1\n",
    "\n",
    "            if self.cur_epoch % 25 == 0:\n",
    "                self.__save_model()\n",
    "\n",
    "            average_loss = epoch_loss / len(dataloader.dataset)  # epoch loss is the sum of each sample's loss since mse reduction is sum\n",
    "            print(f\"Epoch {self.cur_epoch}, Loss: {epoch_loss:.4f}; Average Loss: {average_loss}; lr: {self.scheduler.get_last_lr()}\")\n",
    "\n",
    "        self.model.eval()\n",
    "        return self.__save_returns(losses)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        gt = torch.Tensor([])\n",
    "        preds = torch.Tensor([])\n",
    "        companies = []\n",
    "        for batch, (X, y, co) in enumerate(dataloader):\n",
    "            X = X.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            y_pred = self.model.generate(X, max_len=1)\n",
    "\n",
    "            loss = self.criterion(y, y_pred)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            gt = torch.concat([gt, y], dim=0)\n",
    "            preds = torch.concat([preds, y_pred], dim=0)\n",
    "            companies.extend(co)\n",
    "\n",
    "        print(f\"Average Loss: {total_loss / len(dataloader.dataset)}\")  # total loss is the sum of each sample's loss since mse reduction is sum\n",
    "\n",
    "        gt = gt.to('cpu')\n",
    "        preds = preds.to('cpu')\n",
    "\n",
    "        return gt, preds, companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public methods are constructor, train, evaluate, and load_model\n",
    "# agent for incremental learning models\n",
    "class IncrementalAgent:\n",
    "    def __init__(self, indim, outdim, hidden_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, \n",
    "                 device, checkpoint_dir, init_lr, lr_decay, min_lr, decay_lr_every, tickers):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.tickers = tickers\n",
    "\n",
    "        self.allow_training = True\n",
    "        self.cur_epoch = 0\n",
    "\n",
    "        self.device = device\n",
    "        self.model = BigTransformer(indim, outdim, hidden_dim, d_model, nhead, \n",
    "                                    num_encoder_layers, num_decoder_layers)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=init_lr)\n",
    "\n",
    "        # at epoch e, lr will be init_lr * scheduler_lamb(e)\n",
    "        scheduler_lamb = lambda epoch: max(lr_decay ** (epoch // decay_lr_every), min_lr / init_lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, scheduler_lamb)\n",
    "\n",
    "        self.criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        checkpoint = torch.load(model_path)\n",
    "\n",
    "        self.model.load_state_dict(checkpoint[\"model\"])\n",
    "        self.cur_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "        self.allow_training = False\n",
    "        self.model.eval()\n",
    "\n",
    "    def __save_model(self):\n",
    "        if not os.path.isdir(self.checkpoint_dir):\n",
    "            os.mkdir(self.checkpoint_dir)\n",
    "\n",
    "        dt = datetime.datetime.now().strftime(\"%m-%d_%H-%M-%S\")\n",
    "        path = os.path.join(self.checkpoint_dir, f\"{dt}_agent_{self.cur_epoch}.pth\")\n",
    "\n",
    "        params = {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"epoch\": self.cur_epoch\n",
    "        }\n",
    "\n",
    "        torch.save(params, path)\n",
    "\n",
    "    def __save_returns(self, fn, returns):\n",
    "        returns_prefix = f\"{self.checkpoint_dir}/returns\"\n",
    "\n",
    "        if not os.path.isdir(self.checkpoint_dir):\n",
    "            os.mkdir(self.checkpoint_dir)\n",
    "        if not os.path.isdir(returns_prefix):\n",
    "            os.mkdir(returns_prefix)\n",
    "\n",
    "        np_filename = f\"{returns_prefix}/{fn}{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.npy\"\n",
    "        np.save(np_filename, returns)\n",
    "\n",
    "        return np_filename\n",
    "\n",
    "\n",
    "    def train(self, test_days, epochs):\n",
    "        if not self.allow_training:\n",
    "            raise Exception(\"Not allowed to train after loading\")\n",
    "        \n",
    "\n",
    "        losses = []\n",
    "        predictions = []\n",
    "        ground_truths = []\n",
    "        companies = []\n",
    "\n",
    "        for day in range(test_days):\n",
    "            # create new datasets for each new test_day\n",
    "            train_set = IncrementalDataset(self.tickers, '../data_combined', 30, test_days - day, False)\n",
    "            test_set = IncrementalDataset(self.tickers, '../data_combined', 30, test_days - day, True)\n",
    "            train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "            test_loader = DataLoader(test_set)\n",
    "\n",
    "            losses_per_day = []\n",
    "            self.model.train()\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0\n",
    "                for (X, y, tickers) in train_loader:\n",
    "                    X = X.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "\n",
    "                    y_pred = self.model(X, y)\n",
    "\n",
    "                    loss = self.criterion(y_pred, y)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    # TODO is this good?\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                # self.scheduler.step()\n",
    "\n",
    "                losses_per_day.append(epoch_loss)\n",
    "\n",
    "                self.cur_epoch += 1\n",
    "\n",
    "                if self.cur_epoch % 25 == 0:\n",
    "                    self.__save_model()\n",
    "\n",
    "                average_loss = epoch_loss / len(train_set)  # epoch loss is the sum of each sample's loss since mse reduction is sum\n",
    "                print(f\"Test Day {day}, Epoch {self.cur_epoch}, Loss: {epoch_loss:.4f}; Average Loss: {average_loss}; lr: {self.scheduler.get_last_lr()}\")\n",
    "\n",
    "            gt, pred, tickers = self.evaluate(test_loader)\n",
    "            ground_truths.append(gt)\n",
    "            predictions.append(pred)\n",
    "            companies.extend(tickers)\n",
    "\n",
    "            losses.append(losses_per_day)\n",
    "\n",
    "        ground_truths = np.array(ground_truths)\n",
    "        predictions = np.array(ground_truths)\n",
    "\n",
    "        self.__save_returns('ground_truths_', ground_truths)\n",
    "        self.__save_returns('predictions', predictions)\n",
    "\n",
    "        self.model.eval()\n",
    "        return ground_truths, predictions, companies\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        gt = torch.Tensor([])\n",
    "        preds = torch.Tensor([])\n",
    "        companies = []\n",
    "        for batch, (X, y, co) in enumerate(dataloader):\n",
    "            X = X.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            y_pred = self.model.generate(X, max_len=1)\n",
    "\n",
    "            loss = self.criterion(y_pred, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            gt = torch.concat([gt, y], dim=0)\n",
    "            preds = torch.concat([preds, y_pred], dim=0)\n",
    "            companies.extend(co)\n",
    "\n",
    "        print(f\"Test Loss: {total_loss / len(dataloader.dataset)}\")  # total loss is the sum of each sample's loss since mse reduction is sum\n",
    "\n",
    "        gt = gt.to('cpu').detach().numpy()\n",
    "        preds = preds.to('cpu').detach().numpy()\n",
    "\n",
    "        return gt, preds, companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public methods are constructor, train, evaluate, and load_model\n",
    "# agent for incremental learning models\n",
    "class IncrementalProbAgent:\n",
    "    def __init__(self, indim, outdim, hidden_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, \n",
    "                 device, checkpoint_dir, init_lr, lr_decay, min_lr, decay_lr_every, tickers):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.tickers = tickers\n",
    "\n",
    "        self.allow_training = True\n",
    "        self.cur_epoch = 0\n",
    "\n",
    "        self.device = device\n",
    "        self.model = BigTransformer(indim, outdim, hidden_dim, d_model, nhead, \n",
    "                                    num_encoder_layers, num_decoder_layers)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=init_lr)\n",
    "\n",
    "        # at epoch e, lr will be init_lr * scheduler_lamb(e)\n",
    "        scheduler_lamb = lambda epoch: max(lr_decay ** (epoch // decay_lr_every), min_lr / init_lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, scheduler_lamb)\n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        checkpoint = torch.load(model_path)\n",
    "\n",
    "        self.model.load_state_dict(checkpoint[\"model\"])\n",
    "        self.cur_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "        self.allow_training = False\n",
    "        self.model.eval()\n",
    "\n",
    "    def __save_model(self):\n",
    "        if not os.path.isdir(self.checkpoint_dir):\n",
    "            os.mkdir(self.checkpoint_dir)\n",
    "\n",
    "        dt = datetime.datetime.now().strftime(\"%m-%d_%H-%M-%S\")\n",
    "        path = os.path.join(self.checkpoint_dir, f\"{dt}_agent_{self.cur_epoch}.pth\")\n",
    "\n",
    "        params = {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"epoch\": self.cur_epoch\n",
    "        }\n",
    "\n",
    "        torch.save(params, path)\n",
    "\n",
    "    def __save_returns(self, fn, returns):\n",
    "        returns_prefix = f\"{self.checkpoint_dir}/returns\"\n",
    "\n",
    "        if not os.path.isdir(self.checkpoint_dir):\n",
    "            os.mkdir(self.checkpoint_dir)\n",
    "        if not os.path.isdir(returns_prefix):\n",
    "            os.mkdir(returns_prefix)\n",
    "\n",
    "        np_filename = f\"{returns_prefix}/{fn}{datetime.datetime.now().strftime('%m-%d_%H-%M-%S')}.npy\"\n",
    "        np.save(np_filename, returns)\n",
    "\n",
    "        return np_filename\n",
    "\n",
    "    def train(self, test_days, epochs):\n",
    "        if not self.allow_training:\n",
    "            raise Exception(\"Not allowed to train after loading\")\n",
    "        \n",
    "        losses = []\n",
    "        predictions = []\n",
    "        ground_truths = []\n",
    "        companies = []\n",
    "\n",
    "        for day in range(test_days):\n",
    "            # create new datasets for each new test_day\n",
    "            train_set = IncrementalDataset(self.tickers, '../data_combined', 30, test_days - day, False)\n",
    "            test_set = IncrementalDataset(self.tickers, '../data_combined', 30, test_days - day, True)\n",
    "            train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "            test_loader = DataLoader(test_set)\n",
    "\n",
    "            losses_per_day = []\n",
    "            self.model.train()\n",
    "            for epoch in range(epochs):\n",
    "                epoch_loss = 0\n",
    "                for (X, y, tickers) in train_loader:\n",
    "                    X = X.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "\n",
    "                    y_pred = self.model(X, y) # y_pred will be (B, 1)\n",
    "\n",
    "                    y = y[:,7].clone() # pct_change is 7th column\n",
    "                    y[y <= 0] = 0\n",
    "                    y[y > 0] = 1\n",
    "\n",
    "                    loss = self.criterion(y_pred, y.unsqueeze(1))\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    # TODO is this good?\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                # self.scheduler.step()\n",
    "\n",
    "                losses_per_day.append(epoch_loss)\n",
    "\n",
    "                self.cur_epoch += 1\n",
    "\n",
    "                if self.cur_epoch % 25 == 0:\n",
    "                    self.__save_model()\n",
    "\n",
    "                average_loss = epoch_loss / len(train_set)  # epoch loss is the sum of each sample's loss since mse reduction is sum\n",
    "                print(f\"Test Day {day}, Epoch {self.cur_epoch}, Loss: {epoch_loss:.4f}; Average Loss: {average_loss}; lr: {self.scheduler.get_last_lr()}\")\n",
    "\n",
    "            gt, pred, tickers = self.evaluate(test_loader)\n",
    "            ground_truths.append(gt)\n",
    "            predictions.append(pred)\n",
    "            companies.extend(tickers)\n",
    "\n",
    "            losses.append(losses_per_day)\n",
    "\n",
    "        ground_truths = np.array(ground_truths).squeeze()\n",
    "        predictions = np.array(predictions).squeeze()\n",
    "\n",
    "        self.__save_returns('ground_truths_', ground_truths)\n",
    "        self.__save_returns('predictions', predictions)\n",
    "\n",
    "        self.model.eval()\n",
    "        return ground_truths, predictions, companies\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        gt = torch.Tensor([]).to(self.device)\n",
    "        preds = torch.Tensor([]).to(self.device)\n",
    "        companies = []\n",
    "        for batch, (X, y, co) in enumerate(dataloader):\n",
    "            X = X.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            y_pred = self.model.generate(X, max_len=1)\n",
    "\n",
    "            y = y[:,7].clone() # pct_change is 7th column\n",
    "            y[y <= 0] = 0\n",
    "            y[y > 0] = 1\n",
    "\n",
    "            loss = self.criterion(y_pred, y.unsqueeze(1))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            gt = torch.concat([gt, y.unsqueeze(1)], dim=0)\n",
    "            preds = torch.concat([preds, torch.sigmoid(y_pred)], dim=0)\n",
    "            print(torch.sigmoid(y_pred), y_pred)\n",
    "            companies.extend(co)\n",
    "\n",
    "        print(f\"Test Loss: {total_loss / len(dataloader.dataset)}\")  # total loss is the sum of each sample's loss since mse reduction is sum\n",
    "\n",
    "        gt = gt.to('cpu').detach().numpy()\n",
    "        preds = preds.to('cpu').detach().numpy()\n",
    "\n",
    "        return gt, preds, companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "tickers = [\"AAPL\", \"NVDA\", 'MSFT', 'TSLA', 'AMZN']\n",
    "data_dir = \"../data_combined/\"\n",
    "test_days = 100\n",
    "lag_days = 30\n",
    "batch_size = 128\n",
    "\n",
    "# model params\n",
    "indim = 23\n",
    "outdim = 1\n",
    "hidden_dim = 256\n",
    "d_model = 64\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = VariableLengthDataset(tickers=tickers, data_dir=data_dir, lag_days=lag_days, test_days=test_days, test=False)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = VariableLengthDataset(tickers=tickers, data_dir=data_dir, lag_days=lag_days, test_days=test_days, test=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = BigTransformerAgent(indim=23, outdim=23, hidden_dim=256, d_model=64, nhead=8, num_encoder_layers=6, num_decoder_layers=6, device=device, \n",
    "                            checkpoint_dir='../saved_models/23outdimMSEmodel', init_lr=0.001, lr_decay=0.0001, min_lr=0.0000025, decay_lr_every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train(train_loader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = IncrementalAgent(indim=23, outdim=23, hidden_dim=256, d_model=64, nhead=8, num_encoder_layers=6, num_decoder_layers=6, device=device, \n",
    "                            checkpoint_dir='../saved_models/23outdimIncrementalMSEmodel', init_lr=0.0001, lr_decay=0.5, min_lr=0.00000025, decay_lr_every=10, \n",
    "                            tickers=tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt, preds, companies = agent.train(test_days, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = IncrementalProbAgent(indim=23, outdim=1, hidden_dim=256, d_model=64, nhead=8, num_encoder_layers=6, num_decoder_layers=6, device=device, \n",
    "                            checkpoint_dir='../saved_models/1outdimIncrementalMSEmodel', init_lr=0.0001, lr_decay=0.5, min_lr=0.00000025, decay_lr_every=10, \n",
    "                            tickers=tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Day 0, Epoch 1, Loss: 8195.1470; Average Loss: 0.6918655115927056; lr: [0.0001]\n",
      "tensor([[0.5379]], device='cuda:0') tensor([[0.1517]], device='cuda:0')\n",
      "tensor([[0.5335]], device='cuda:0') tensor([[0.1342]], device='cuda:0')\n",
      "tensor([[0.5373]], device='cuda:0') tensor([[0.1496]], device='cuda:0')\n",
      "tensor([[0.5405]], device='cuda:0') tensor([[0.1623]], device='cuda:0')\n",
      "tensor([[0.5422]], device='cuda:0') tensor([[0.1692]], device='cuda:0')\n",
      "Test Loss: 0.7728010892868042\n",
      "Test Day 1, Epoch 2, Loss: 8204.5600; Average Loss: 0.6923679314786372; lr: [0.0001]\n",
      "tensor([[0.5384]], device='cuda:0') tensor([[0.1538]], device='cuda:0')\n",
      "tensor([[0.5343]], device='cuda:0') tensor([[0.1375]], device='cuda:0')\n",
      "tensor([[0.5384]], device='cuda:0') tensor([[0.1538]], device='cuda:0')\n",
      "tensor([[0.5418]], device='cuda:0') tensor([[0.1674]], device='cuda:0')\n",
      "tensor([[0.5423]], device='cuda:0') tensor([[0.1698]], device='cuda:0')\n",
      "Test Loss: 0.6514679670333863\n",
      "Test Day 2, Epoch 3, Loss: 8206.0055; Average Loss: 0.6921978510064648; lr: [0.0001]\n",
      "tensor([[0.5390]], device='cuda:0') tensor([[0.1562]], device='cuda:0')\n",
      "tensor([[0.5342]], device='cuda:0') tensor([[0.1371]], device='cuda:0')\n",
      "tensor([[0.5386]], device='cuda:0') tensor([[0.1548]], device='cuda:0')\n",
      "tensor([[0.5417]], device='cuda:0') tensor([[0.1673]], device='cuda:0')\n",
      "tensor([[0.5424]], device='cuda:0') tensor([[0.1701]], device='cuda:0')\n",
      "Test Loss: 0.6486466526985168\n",
      "Test Day 3, Epoch 4, Loss: 8205.0846; Average Loss: 0.6918283825982079; lr: [0.0001]\n",
      "tensor([[0.5394]], device='cuda:0') tensor([[0.1579]], device='cuda:0')\n",
      "tensor([[0.5346]], device='cuda:0') tensor([[0.1387]], device='cuda:0')\n",
      "tensor([[0.5376]], device='cuda:0') tensor([[0.1509]], device='cuda:0')\n",
      "tensor([[0.5432]], device='cuda:0') tensor([[0.1732]], device='cuda:0')\n",
      "tensor([[0.5434]], device='cuda:0') tensor([[0.1739]], device='cuda:0')\n",
      "Test Loss: 0.6818292260169982\n",
      "Test Day 4, Epoch 5, Loss: 8212.1422; Average Loss: 0.6921316604196297; lr: [0.0001]\n",
      "tensor([[0.5399]], device='cuda:0') tensor([[0.1598]], device='cuda:0')\n",
      "tensor([[0.5350]], device='cuda:0') tensor([[0.1403]], device='cuda:0')\n",
      "tensor([[0.5360]], device='cuda:0') tensor([[0.1441]], device='cuda:0')\n",
      "tensor([[0.5439]], device='cuda:0') tensor([[0.1761]], device='cuda:0')\n",
      "tensor([[0.5437]], device='cuda:0') tensor([[0.1752]], device='cuda:0')\n",
      "Test Loss: 0.6487607836723328\n"
     ]
    }
   ],
   "source": [
    "true_labels, predicted_scores, companies = agent.train(5, 1) # one column for each company ticker, flatten to compute ROC over all\n",
    "fpr, tpr, thresholds = roc_curve(true_labels.reshape(-1), predicted_scores.reshape(-1))\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1., 1.],\n",
       "        [1., 1., 0., 1., 0.],\n",
       "        [0., 1., 1., 1., 1.]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1.],\n",
       "        [1., 1., 0., 1., 1.],\n",
       "        [1., 1., 0., 1., 0.],\n",
       "        [0., 1., 1., 1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels, predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
